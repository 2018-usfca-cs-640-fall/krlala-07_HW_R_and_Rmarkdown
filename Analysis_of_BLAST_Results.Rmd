---
title: "Analysis of BLAST Results"
author: "Don Francisco"
date: "October 21, 2018"
output: github_document
---

# Introduction

Bacteria are ubiquitous, and the human body is no exception. Humans house huge swathes of bacteria inside and on them. These bacteria play very important roles in human health, especially in areas like the face and gut. The human microbiome project by the NIH provided a lot of information with regards to these microbial communities, including the common species found and sequences as well.

In the Fierer et al study, they attempt to analyse whether communities of microbes found on a persons hands can be matched to the computer mouse they utilised. Skin bacterial communities are personalized, and there is evidence that the interindividual variability among such communities is enough to identify the source. The study shows that microbial communities from such surfaces can be used to distinguish individuals to some degree, even if those objects have been left untouched for up to 2 weeks at room temperature, and hence serve as a method of forensic analysis.

# Methods

Bacterial communities found on individuals fingers were compared with the communities obtained from keys on 3 different keyboards. The samples collected from the surfaces were then comapred with a database of 250 individuals, to macth with the correct individual that had touched the surface in question. Individaulkeys and the fingertip oof the owner were swabbed, and these swabs were stored at -80'C before extracting DNA.

## Sample origin and sequencing

Samples came from computer keys, mice, and humanhands and fingertips. DNA collected using “MO BIO PowerSoil” DNA Isolation kit, 16S rRNA genes camplified by PCR. PyroSequencing was then carried out by 454 Life Sciences Genome Sequencer FLX instrument and sequences with less than 300 bp are not included.

## Computational

Further computational steps were used to analyze the data. The data was downloaded from NCBI, and then its quality was assessed by generating QC reports. The Trimmomatic tool was then used to 'trim' sequences, eliminating low quality reads and "N" in the sequence reads. Finally, these trimmed results were converted to the fasta format and then were used to BLAST and find the top matches for the sequences, all using a bash script.

# Results

```{r load-libraries, message = FALSE}
# Be sure to install these packages before running this script
# They can be installed either with the install.packages() function
# or with the 'Packages' pane in RStudio

# load packages
library("dplyr")
library("tidyr")
library("knitr")
library("ggplot2")
```

```{r make-read-in-data-function}
# Output format from BLAST is as detailed on:
# https://www.ncbi.nlm.nih.gov/books/NBK279675/
# In this case, we used: '10 sscinames std'
# 10 means csv format
# sscinames means unique Subject Scientific Name(s), separated by a ';'
# std means the standard set of result columns, which are:
# 'qseqid sseqid pident length mismatch
# gapopen qstart qend sstart send evalue bitscore',


# this function takes as input a quoted path to a BLAST result file
# and produces as output a dataframe with proper column headers
# and the 'qseqid' column split into sample and seq number
read_blast_output <- function(filename) {
  data_in <- read.csv(filename,
                      header = FALSE, # files don't have column names in them
                      col.names = c("sscinames", # unique Subject Sci Name(s)
                                    "qseqid",    # Query Seq-id
                                    "sseqid",    # Subject Seq-id
                                    "pident",    # Percntge of identical matches
                                    "length",    # Alignment length
                                    "mismatch",  # Number of mismatches
                                    "gapopen",   # Number of gap openings
                                    "qstart",    # Start of alignment in query
                                    "qend",      # End of alignment in query
                                    "sstart",    # Start of alignment in subj
                                    "send",      # End of alignment in subject
                                    "evalue",    # Expect value
                                    "bitscore"))  # Bit score

  # Next we want to split the query sequence ID into
  # Sample and Number components so we can group by sample
  # They originally look like "ERR1942280.1"
  # and we want to split that into two columns: "ERR1942280" and "1"
  # we can use the separate() function from the tidyr library to do this
  # Note that we have to double escape the period for this to work
  # the syntax is
  # separate(column_to_separate,
  # c("New_column_name_1", "New_column_name_2"),
  # "seperator")
  data_in <- data_in %>%
    separate(qseqid, c("sample_name", "sample_number"), "\\.")
}
```

```{r read-in-BLAST-data}
# this makes a vector of all the BLAST output file names, including
# the name(s) of the directories they are in
files_to_read_in <- list.files(path = "output/blast",
                               full.names = TRUE)

# We need to create an empty matrix with the right number of columns
# so that we can rbind() each dataset on to it
joined_blast_data <- matrix(nrow = 0,
                            ncol = 14)

# now we loop over each of the files in the list and append them
# to the bottom of the 'joined_blast_data' object
# we do this with the rbind() function and the function we
# made earlier to read in the files, read_blast_output()
for (filename in files_to_read_in) {
  joined_blast_data <- rbind(joined_blast_data,
                             read_blast_output(filename))
}
```

```{r read-in-metadata-and-join}
# Next we want to read in the metadata file so we can add that in too
# This is not a csv file, so we have to use a slightly different syntax
# here the `sep = "\t"` tells the function that the data are tab-delimited
# and the `stringsAsFactors = FALSE` tells it not to assume that things are
# categorical variables
metadata_in <- read.table(paste0("data/metadata/",
                                 "fierer_forensic_hand_mouse_SraRunTable.txt"),
                          sep = "\t",
                          header = TRUE,
                          stringsAsFactors = FALSE)

# Finally we use the left_join() function from dplyr to merge or 'join' the
# combined data and metadata into one big table, so it's easier to work with
# in R the `by = c("Run_s" = "sample_name")` syntax tells R which columns
# to match up when joining the datasets together
joined_blast_data_metadata <- metadata_in %>%
  left_join(joined_blast_data,
            by = c("Run_s" = "sample_name"))
```


```{r histograms}
# Here we're using the dplyr piping syntax to select a subset of rows matching a
# criteria we specify (using the filter) function, and then pull out a column
# from the data to make a histogram.
joined_blast_data_metadata %>%
  filter(sscinames == "unidentified bacterium" ) %>%
  ggplot(aes(x = host_subject_id_s )) +
    geom_bar() + 
    ggtitle("Percent Identity") +
    xlab("sscinames")

joined_blast_data_metadata %>%
  filter(sscinames == "Bartonella washoensis" ) %>%
  ggplot(aes(x = host_subject_id_s )) +
    geom_bar() + 
    ggtitle("Percent Identity") +
    xlab("sscinames")

joined_blast_data_metadata %>%
  filter(host_subject_id_s == "M2", ) %>%
  ggplot(aes(x= sscinames, y = sample_type_s, color= pident )) +
    geom_point() + 
    ggtitle("Percent Identity") +
    xlab("sscinames")


joined_blast_data_metadata %>%
  filter(host_subject_id_s == "F7", ) %>%
  ggplot(aes(x= sscinames, y = sample_type_s, color= pident )) +
    geom_point() + 
    ggtitle("Percent Identity") +
    xlab("sscinames")
```
Don't forget to report what your figures show in words, here in the Results section.

```{r summary-table}
# Finally, we'd like to be able to make a summary table of the counts of
# sequences for each subject for both sample types. To do that we can use the
# table() function. We add the kable() function as well (from the tidyr package)
# in order to format the table nicely when the document is knitted
kable(table(joined_blast_data_metadata$host_subject_id_s,
            joined_blast_data_metadata$sample_type_s))
```

# Discussion

Add 2-3 paragraphs here interpreting your results and considering future directions one might take in analyzing these data.

